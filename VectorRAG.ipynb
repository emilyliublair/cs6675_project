{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pinecone import Pinecone\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Pinecone client with your API key\n",
    "load_dotenv()\n",
    "pineAPI = os.getenv(\"PINECONE_API\")\n",
    "pc = Pinecone(api_key=pineAPI )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dense index with integrated embedding\n",
    "index_name = \"dense-index\"\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index_for_model(\n",
    "        name=index_name,\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\",\n",
    "        embed={\n",
    "            \"model\":\"llama-text-embed-v2\",\n",
    "            \"field_map\":{\"text\": \"chunk_text\"}\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for parsing\n",
    "num_docs = 0\n",
    "labs  = [\"lab0\", \"lab1\", \"lab2\", \"lab3\"]\n",
    "records = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proccesed  320 documents\n"
     ]
    }
   ],
   "source": [
    "# parse documents\n",
    "import os\n",
    "import re\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "def parse_lab_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    question_match = re.search(r'Question:\\s*(.*?)(?=Student Answer:|$)', content, re.DOTALL)\n",
    "    student_answer_match = re.search(r'Student Answer:\\s*(.*?)(?=Instructor Answer:|$)', content, re.DOTALL)\n",
    "    instructor_answer_match = re.search(r'Instructor Answer:\\s*(.*?)(?=Followup Discussions:|$)', content, re.DOTALL)\n",
    "    followup_match = re.search(r'Followup Discussions:\\s*(.*?)$', content, re.DOTALL)\n",
    "    \n",
    "    # Extract the content for each section, strip whitespace\n",
    "    question = question_match.group(1).strip() if question_match else \"\"\n",
    "    student_answer = student_answer_match.group(1).strip() if student_answer_match else \"\"\n",
    "    instructor_answer = instructor_answer_match.group(1).strip() if instructor_answer_match else \"\"\n",
    "    followups = followup_match.group(1).strip() if followup_match else \"\"\n",
    "    \n",
    "    # Create structured document\n",
    "    return {\n",
    "        \"file_name\": os.path.basename(file_path),\n",
    "        \"question\": question,\n",
    "        \"student_answer\": student_answer,\n",
    "        \"instructor_answer\": instructor_answer,\n",
    "        \"followups\": followups\n",
    "    }\n",
    "\n",
    "def process_lab_files(folder_path):\n",
    "    results = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            parsed_data = parse_lab_file(file_path)\n",
    "            results.append(parsed_data)\n",
    "    return results\n",
    "\n",
    "def format_for_rag(parsed_data, category):\n",
    "    global num_docs\n",
    "    rag_documents = []\n",
    "    \n",
    "    for i, item in enumerate(parsed_data):\n",
    "        doc_id = f\"rec{num_docs}\"\n",
    "        num_docs += 1\n",
    "        \n",
    "        # Format text the same way as before\n",
    "        formatted_text = f\"\"\"Question:{item['question']}\n",
    "        Student Answer:{item['student_answer']}\n",
    "        Instructor Answer:{item['instructor_answer']}\n",
    "        Followup Discussions:{item['followups']}\"\"\".strip()\n",
    "        \n",
    "        # Create record dictionary\n",
    "        record = {\n",
    "            \"_id\": doc_id,\n",
    "            \"chunk_text\": formatted_text,\n",
    "            \"category\": category\n",
    "        }\n",
    "        \n",
    "        rag_documents.append(record)\n",
    "    \n",
    "    return rag_documents\n",
    "\n",
    "for lab in labs:\n",
    "    cur_parsed = process_lab_files(lab)\n",
    "    cur_raw_docs = format_for_rag(cur_parsed, lab)\n",
    "    records.extend(cur_raw_docs)\n",
    "\n",
    "print(\"Proccesed \", num_docs, \"documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserted batch 1 (96 records)\n",
      "Upserted batch 2 (96 records)\n",
      "Upserted batch 3 (96 records)\n",
      "Upserted batch 4 (32 records)\n",
      "Total records upserted: 320\n"
     ]
    }
   ],
   "source": [
    "batch_size = 96\n",
    "dense_index = pc.Index(index_name)\n",
    "for i in range(0, len(records), batch_size):\n",
    "    batch = records[i:i+batch_size]\n",
    "    dense_index.upsert_records(\"example-namespace\", batch)\n",
    "    print(f\"Upserted batch {i//batch_size + 1} ({len(batch)} records)\")\n",
    "\n",
    "print(f\"Total records upserted: {len(records)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "stats = dense_index.describe_index_stats()\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.exceptions import PineconeApiException \n",
    "def ask_query(query, debug):\n",
    "    try:\n",
    "\n",
    "        results = dense_index.search(\n",
    "            namespace=\"example-namespace\",\n",
    "            query={\n",
    "                \"top_k\": 10,\n",
    "                \"inputs\": {\n",
    "                    'text': query\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            reranked_results = dense_index.search(\n",
    "                namespace=\"example-namespace\",\n",
    "                query={\n",
    "                    \"top_k\": 10,\n",
    "                    \"inputs\": {\n",
    "                        'text': query\n",
    "                    }\n",
    "                },\n",
    "                rerank={\n",
    "                    \"model\": \"bge-reranker-v2-m3\",\n",
    "                    \"top_n\": 10,\n",
    "                    \"rank_fields\": [\"chunk_text\"]\n",
    "                }   \n",
    "            )\n",
    "            search_results = reranked_results\n",
    "        except PineconeApiException as e:\n",
    "            # If reranking fails due to token limits, fall back to regular search results\n",
    "            if debug:\n",
    "                print(f\"Reranking failed: Using standard search results instead.\")\n",
    "            search_results = results\n",
    "            \n",
    "        context_docs = []\n",
    "        for hit in search_results['result']['hits']:\n",
    "            context_docs.append(f\"Category: {hit['fields']['category']}\\n{hit['fields']['chunk_text']}\")\n",
    "        \n",
    "        return context_docs\n",
    "    except PineconeApiException as e:\n",
    "        print(f\"Search failed: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "#example: ask_query(\"For lab 0, It says that we have to make a temporary file, does this imply we should delete the file before exiting helloworld.c?lab0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\") \n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, context_docs):\n",
    "    # Prepare context from retrieved documents\n",
    "    context = \"\\n\\n\".join([f\"Document {i+1}:\\n{doc}\" for i, doc in enumerate(context_docs)])\n",
    "    \n",
    "    # Create prompt with context and query\n",
    "    prompt = f\"\"\" You are an AI assistant for a computer science course. Use the following retrieved documents to answer the question. If you don't know the answer, just say that you don't know, don't try to make up an answer. Context:\n",
    "    {context}\n",
    "    Question: {query}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    # Call OpenAI API\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",  \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant for a computer science course.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def intake_question(query):\n",
    "    context = ask_query(query, False)\n",
    "    return generate_response(query, context)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question in lab3 whu might I be failing test case 11?\n",
      "Based on the information provided in the retrieved documents, it seems that failing test case 11 in lab3 could be due to issues related to stack management. Specifically, there was a mention of a stack issue where the child stack was not copying the last return address, causing a trap. Additionally, there was a mention of an error occurring when cloning a clone, which was identified using gdb for diagnosis.\n",
      "\n",
      "Therefore, it is possible that the failure in test case 11 could be related to stack management or cloning issues. It might be helpful to review the stack implementation and cloning logic in your code to identify and address any potential issues that could be causing the test case to fail.\n"
     ]
    }
   ],
   "source": [
    "# Sample run\n",
    "query = input(\"Enter question:\")\n",
    "print(\"question\", query)\n",
    "response = intake_question(query)\n",
    "print(response)\n",
    "# query = input(\"Enter question:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN UP: USE TO DELETE INDEX\n",
    "pc.delete_index(index_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
